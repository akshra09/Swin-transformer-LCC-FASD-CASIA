{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3405616,"sourceType":"datasetVersion","datasetId":2052800}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision\nfrom torchvision import datasets\nfrom torchvision import transforms as T # for simplifying the transforms\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader, sampler, random_split\nfrom torchvision import models","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:23:14.390038Z","iopub.status.idle":"2024-04-14T15:23:14.390574Z","shell.execute_reply.started":"2024-04-14T15:23:14.390292Z","shell.execute_reply":"2024-04-14T15:23:14.390313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:23:14.392178Z","iopub.status.idle":"2024-04-14T15:23:14.392665Z","shell.execute_reply.started":"2024-04-14T15:23:14.392405Z","shell.execute_reply":"2024-04-14T15:23:14.392423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:23:14.394231Z","iopub.status.idle":"2024-04-14T15:23:14.394724Z","shell.execute_reply.started":"2024-04-14T15:23:14.394451Z","shell.execute_reply":"2024-04-14T15:23:14.394471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nfrom tqdm import tqdm\nimport time\nimport copy","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:23:14.396183Z","iopub.status.idle":"2024-04-14T15:23:14.396642Z","shell.execute_reply.started":"2024-04-14T15:23:14.396399Z","shell.execute_reply":"2024-04-14T15:23:14.396418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:23:14.398311Z","iopub.status.idle":"2024-04-14T15:23:14.398670Z","shell.execute_reply.started":"2024-04-14T15:23:14.398481Z","shell.execute_reply":"2024-04-14T15:23:14.398495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_classes(data_dir):\n    all_data = datasets.ImageFolder(data_dir)\n    return all_data.classes","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:23:14.400144Z","iopub.status.idle":"2024-04-14T15:23:14.400480Z","shell.execute_reply.started":"2024-04-14T15:23:14.400321Z","shell.execute_reply":"2024-04-14T15:23:14.400335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/lcc-fasd-casia-combined/lcc-fasd-casia/LCC_FASD'\nbatch_size = 32","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:23:14.401837Z","iopub.status.idle":"2024-04-14T15:23:14.402168Z","shell.execute_reply.started":"2024-04-14T15:23:14.401999Z","shell.execute_reply":"2024-04-14T15:23:14.402023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_swin_transformer_data_loaders(data_dir, batch_size, train=True, image_size=(224, 224)):\n    if train:\n        # Train data transformations\n        transform = transforms.Compose([\n            transforms.RandomResizedCrop(image_size),\n            transforms.RandomHorizontalFlip(),\n            transforms.ToTensor(),\n        ])\n        dataset = datasets.ImageFolder(os.path.join(data_dir, \"LCC_FASD_training/\"), transform=transform)\n        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n        return data_loader, len(dataset)\n    else:\n        # Validation/test data transformations\n        transform = transforms.Compose([\n            transforms.Resize(image_size),\n            transforms.CenterCrop(image_size),\n            transforms.ToTensor(),\n        ])\n        val_dataset = datasets.ImageFolder(os.path.join(data_dir, \"LCC_FASD_development/\"), transform=transform)\n        test_dataset = datasets.ImageFolder(os.path.join(data_dir, \"LCC_FASD_evaluation/\"), transform=transform)\n        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n        return val_loader, test_loader, len(val_dataset), len(test_dataset)\n\n(train_loader, train_data_len) = get_swin_transformer_data_loaders(data_dir, batch_size, train=True)\n(val_loader, test_loader, val_data_len, test_data_len) = get_swin_transformer_data_loaders(data_dir, batch_size, train=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:23:14.403136Z","iopub.status.idle":"2024-04-14T15:23:14.403440Z","shell.execute_reply.started":"2024-04-14T15:23:14.403291Z","shell.execute_reply":"2024-04-14T15:23:14.403303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndataset_path = \"/kaggle/input/lcc-fasd-casia-combined\"","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:23:14.404964Z","iopub.status.idle":"2024-04-14T15:23:14.405432Z","shell.execute_reply.started":"2024-04-14T15:23:14.405194Z","shell.execute_reply":"2024-04-14T15:23:14.405213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = get_classes(\"/kaggle/input/lcc-fasd-casia-combined/lcc-fasd-casia/LCC_FASD/LCC_FASD_training\")\nprint(classes, len(classes))","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:23:14.406778Z","iopub.status.idle":"2024-04-14T15:23:14.408786Z","shell.execute_reply.started":"2024-04-14T15:23:14.406949Z","shell.execute_reply":"2024-04-14T15:23:14.406969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = get_classes(\"/kaggle/input/lcc-fasd-casia-combined/lcc-fasd-casia/LCC_FASD/LCC_FASD_evaluation\")\nprint(classes, len(classes))","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:23:14.410094Z","iopub.status.idle":"2024-04-14T15:23:14.410561Z","shell.execute_reply.started":"2024-04-14T15:23:14.410310Z","shell.execute_reply":"2024-04-14T15:23:14.410329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = get_classes(\"/kaggle/input/lcc-fasd-casia-combined/lcc-fasd-casia/LCC_FASD/LCC_FASD_development\")\nprint(classes, len(classes))","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:23:14.411783Z","iopub.status.idle":"2024-04-14T15:23:14.412236Z","shell.execute_reply.started":"2024-04-14T15:23:14.411993Z","shell.execute_reply":"2024-04-14T15:23:14.412012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataloaders = {\n    \"train\": train_loader,\n    \"val\": val_loader\n}\ndataset_sizes = {\n    \"train\": train_data_len,\n    \"val\": val_data_len\n}","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:23:14.413669Z","iopub.status.idle":"2024-04-14T15:23:14.413994Z","shell.execute_reply.started":"2024-04-14T15:23:14.413837Z","shell.execute_reply":"2024-04-14T15:23:14.413851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_loader), len(val_loader), len(test_loader))","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:23:14.415747Z","iopub.status.idle":"2024-04-14T15:23:14.416069Z","shell.execute_reply.started":"2024-04-14T15:23:14.415912Z","shell.execute_reply":"2024-04-14T15:23:14.415925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data_len, val_data_len, test_data_len)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:23:14.416977Z","iopub.status.idle":"2024-04-14T15:23:14.417276Z","shell.execute_reply.started":"2024-04-14T15:23:14.417124Z","shell.execute_reply":"2024-04-14T15:23:14.417136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now, for the model\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:23:14.418342Z","iopub.status.idle":"2024-04-14T15:23:14.418672Z","shell.execute_reply.started":"2024-04-14T15:23:14.418488Z","shell.execute_reply":"2024-04-14T15:23:14.418501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HUB_URL = \"SharanSMenon/swin-transformer-hub:main\"\nMODEL_NAME = \"swin_tiny_patch4_window7_224\"\n# check hubconf for more models.\nmodel = torch.hub.load(HUB_URL, MODEL_NAME, pretrained=True) # load from torch hub","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:23:14.420074Z","iopub.status.idle":"2024-04-14T15:23:14.420401Z","shell.execute_reply.started":"2024-04-14T15:23:14.420239Z","shell.execute_reply":"2024-04-14T15:23:14.420254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor param in model.parameters(): #freeze model\n    param.requires_grad = False\n\nn_inputs = model.head.in_features\nmodel.head = nn.Sequential(\n    nn.Linear(n_inputs, 512),\n    nn.ReLU(),\n    nn.Dropout(0.3),\n    nn.Linear(512, len(classes))\n)\nmodel = model.to(device)\nprint(model.head)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:23:14.421871Z","iopub.status.idle":"2024-04-14T15:23:14.422192Z","shell.execute_reply.started":"2024-04-14T15:23:14.422034Z","shell.execute_reply":"2024-04-14T15:23:14.422047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Now, we import timm, torchvision image models\n!pip install timm # kaggle doesnt have it installed by default\nimport timm\nfrom timm.loss import LabelSmoothingCrossEntropy # This is better than normal nn.CrossEntropyLoss","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:23:14.423485Z","iopub.status.idle":"2024-04-14T15:23:14.423850Z","shell.execute_reply.started":"2024-04-14T15:23:14.423688Z","shell.execute_reply":"2024-04-14T15:23:14.423702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = LabelSmoothingCrossEntropy()\ncriterion = criterion.to(device)\noptimizer = optim.AdamW(model.head.parameters(), lr=0.005)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:23:14.425103Z","iopub.status.idle":"2024-04-14T15:23:14.425449Z","shell.execute_reply.started":"2024-04-14T15:23:14.425279Z","shell.execute_reply":"2024-04-14T15:23:14.425294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lr scheduler\nexp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.97)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:23:14.427030Z","iopub.status.idle":"2024-04-14T15:23:14.427471Z","shell.execute_reply.started":"2024-04-14T15:23:14.427183Z","shell.execute_reply":"2024-04-14T15:23:14.427277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs=10):\n    since = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch}/{num_epochs - 1}')\n        print(\"-\"*10)\n\n        for phase in ['train', 'val']: # We do training and validation phase per epoch\n            if phase == 'train':\n                model.train() # model to training mode\n            else:\n                model.eval() # model to evaluate\n\n            running_loss = 0.0\n            running_corrects = 0.0\n\n            for inputs, labels in tqdm(dataloaders[phase]):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase == 'train'): # no autograd makes validation go faster\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1) # used for accuracy\n                    loss = criterion(outputs, labels)\n\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            if phase == 'train':\n                scheduler.step() # step at end of epoch\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc =  running_corrects.double() / dataset_sizes[phase]\n            print(\"{} Loss: {:.4f} Acc: {:.4f}\".format(phase, epoch_loss, epoch_acc))\n\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict()) # keep the best validation accuracy model\n        print()\n    time_elapsed = timm.time() - since # slight error\n    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n    print(\"Best Val Acc: {:.4f}\".format(best_acc))\n\n    model.load_state_dict(best_model_wts)\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:23:14.428720Z","iopub.status.idle":"2024-04-14T15:23:14.429059Z","shell.execute_reply.started":"2024-04-14T15:23:14.428899Z","shell.execute_reply":"2024-04-14T15:23:14.428913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_fit = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=300) # now it is a lot faster","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:23:14.430199Z","iopub.status.idle":"2024-04-14T15:23:14.430503Z","shell.execute_reply.started":"2024-04-14T15:23:14.430348Z","shell.execute_reply":"2024-04-14T15:23:14.430360Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss = 0.0\nclass_correct = list(0 for i in range(len(classes)))\nclass_total = list(0 for i in range(len(classes)))\nmodel_fit.eval()\n\nfor data, target in tqdm(test_loader):\n    data, target = data.to(device), target.to(device)\n    with torch.no_grad(): # turn off autograd for faster testing\n        output = model_fit(data)\n        loss = criterion(output, target)\n    test_loss = loss.item() * data.size(0)\n    _, pred = torch.max(output, 1)\n    correct_tensor = pred.eq(target.data.view_as(pred))\n    correct = np.squeeze(correct_tensor.cpu().numpy())\n    if len(target) == 32:\n        for i in range(32):\n            label = target.data[i]\n            class_correct[label] += correct[i].item()\n            class_total[label] += 1\n\ntest_loss = test_loss / test_data_len\nprint('Test Loss: {:.4f}'.format(test_loss))\nfor i in range(len(classes)):\n    if class_total[i] > 0:\n        print(\"Test Accuracy of %5s: %2d%% (%2d/%2d)\" % (\n            classes[i], 100*class_correct[i]/class_total[i], np.sum(class_correct[i]), np.sum(class_total[i])\n        ))\n    else:\n        print(\"Test accuracy of %5s: NA\" % (classes[i]))\nprint(\"Test Accuracy of %2d%% (%2d/%2d)\" % (\n            100*np.sum(class_correct)/np.sum(class_total), np.sum(class_correct), np.sum(class_total)\n        ))","metadata":{"execution":{"iopub.status.busy":"2024-04-14T15:23:14.431891Z","iopub.status.idle":"2024-04-14T15:23:14.432224Z","shell.execute_reply.started":"2024-04-14T15:23:14.432062Z","shell.execute_reply":"2024-04-14T15:23:14.432074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}